{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY-78aCf5hg5"
   },
   "source": [
    "## Eigenvector and Eigenvalue\n",
    "### Notations and Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nox3PSyX5hg6"
   },
   "source": [
    "There are several ways to define eigenvectors and eigenvalues, the most common approach defines an eigenvector of a **square** matrix $A$ (must be square such that this problem is valid) as a vector $\\boldsymbol u$ that satisfies the following equation:\n",
    "$$\n",
    "A\\boldsymbol u =\\lambda \\boldsymbol u\n",
    "$$\n",
    "We can rearrange the equation:\n",
    "$$\n",
    "(A-\\lambda I)\\boldsymbol u =\\boldsymbol 0\n",
    "$$\n",
    "where $λ$ is a scalar termed as eigenvalue coresponding and $\\boldsymbol u$ is a vector termed as to eigenvector. Note that there exist mutiple eigenvalues and eigenvectors of $A$ and they always come as a pair. If we put together all eigenvectors of $A$ in a matrix denoted by $U$ (each column of U is an eigenvector of $A$) and all eigenvalues of $A$ are placed in a diagonal matrix (denoted by $\\Lambda$) where all the other entries are zero values, we can rewrite the first equation as:\n",
    "$$AU=U\\Lambda$$\n",
    "or also as:\n",
    "$$A=U\\Lambda U^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI-uCeYx5hhA"
   },
   "source": [
    "### Examples\n",
    "Let's look at an example of computing eigenvaules and eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0rAl43O55hhA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFkan1Fg5hhB"
   },
   "source": [
    "Firstly, you need to import a necessary package `numpy`. \n",
    "* numpy: a numerical computing package for basic mathematical problems and common operations, such as matrix multiplication (`np.dot`) and matrix reshaping (`numpy.reshape`) which could reshape a matrix to our needed shape\n",
    "* `np.linalg.eig`: a function to compute eigenvectors and eigenvalues of a square matrix.\n",
    "* `np.array`: creates a numpy array\n",
    "* `np.dot`: matrix multiplication function\n",
    "* `np.identity`: creates a identity matrix\n",
    "* `np.linalg.inv`: a function to compute an inverse matrix\n",
    "* `np.diag`: creates a diagonal matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvarcPbT5hhB",
    "outputId": "cc0bda4b-1109-4aad-9599-70544115c3c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 4],\n",
       "       [4, 8, 6],\n",
       "       [1, 2, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2,4],[4,8,6],[1,2,1]])\n",
    "# Create a matrix A\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpe0OgnP5hhB",
    "outputId": "64c8c47c-cb1d-4da9-e166-278006f5dc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first eigen value of A: 10.656854\n",
      "first eigen vector of A\n",
      "[-0.28528127 -0.9322327  -0.22261356]\n"
     ]
    }
   ],
   "source": [
    "eig_val, eig_vec = eig(A)\n",
    "print(\"first eigen value of A: %f\" %(eig_val[0]))\n",
    "print(\"first eigen vector of A\")\n",
    "print(eig_vec[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2nJshFL5hhC"
   },
   "source": [
    "We could multiply them and see if it satisfy the definition equation $(A-\\lambda I)\\boldsymbol u =\\boldsymbol 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-lA_aTv5hhC",
    "outputId": "7ce86eb4-c12e-473b-fc27-5b2889b3dac8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.22044605e-15, -5.32907052e-15, -1.33226763e-15])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = np.identity(3)\n",
    "np.dot((A-eig_val[0]*I),eig_vec[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfWaZO4p5hhC"
   },
   "source": [
    "It should be a zero vector, yet its elements have some very small values. However, the errors are quite small which are acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5UpQ-pM5hhC",
    "outputId": "dffef7a2-3937-4125-863a-7d1e8a7e6306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 4.],\n",
       "       [4., 8., 6.],\n",
       "       [1., 2., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = eig_vec\n",
    "Lambda = np.diag(eig_val)\n",
    "\n",
    "np.dot(np.dot(U,Lambda),np.linalg.inv(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWYutHNP5hhD"
   },
   "source": [
    "We could see that it satisfy the condition $A=U\\Lambda U^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xPm_oLB5hhD"
   },
   "source": [
    "## Positive definite and semi-definite matrices \n",
    "### Notations and Definition \n",
    "\n",
    "\n",
    "In linear algebra, a $n \\times n$ symmetric square real matrix $A$ is said to be **positive definite** if the scalar $\\boldsymbol u^T A \\boldsymbol u$ is strictly positive for every non-zero column vector $\\boldsymbol u$ of $n$ real numbers. **Positive semi-definite matrices** are defined similarly, except that the above scalars $\\boldsymbol u^T A \\boldsymbol u$ must be positive or zero (i.e. non-negative). In other words, for a positive definite matrix, all of its eigenvalues must be strictly positive. For a positive semi-definite matrix, some of its eigenvalues could be zeros, but all its eigenvalues must be non-negative. Both positive definite and semi-definite matrices should be symmetric. Many matrices such as correlation matrices, covariance, cross-product matrices, etc are more likely to be positive semi-definite.\n",
    "\n",
    "Eigenvectors of a positive definite or semi-definite matrix are pairwise orthogonal when their eigenvalues are different. The eigenvectors are also composed of real values. Because eigenvectors corresponding to different eigenvalues are orthogonal, it is possible to store all the eigenvectors in an orthogonal matrix (recall that a matrix is orthogonal when the product of this matrix by its transpose is a diagonal matrix). This implies the following equality:\n",
    "\n",
    "$$U^{−1} = U^T$$\n",
    "\n",
    "We can, therefore, express the positive definite or semi-definite matrix A as:\n",
    "\n",
    "$$A=U\\Lambda U^T$$\n",
    "\n",
    "where $U^TU = I$ are the normalized eigenvectors; if they are not normalized then $U^TU$ is a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H89jOUnh5hhD"
   },
   "source": [
    "### Examples\n",
    "Let's see an example. Firstly, we establish a square matrix of $A$ by $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wul7pCmG5hhD",
    "outputId": "2cc3a7c2-6d1f-44cc-a90e-94dcfe9cf95c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21,  44,   9],\n",
       "       [ 44, 116,  26],\n",
       "       [  9,  26,   6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,2,4],[4,8,6],[1,2,1]])\n",
    "A = np.dot(X,X.T)\n",
    "# Create a matrix A\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9GDP7mj5hhE"
   },
   "source": [
    "Then we calculate the $U$ and $\\Lambda$ as `U` and `Lambda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aCFpY9tG5hhE",
    "outputId": "eb4cc96d-1815-495f-897e-ed7dfcaef233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.38933300e+02  4.06669962e+00 -1.41724797e-15]\n"
     ]
    }
   ],
   "source": [
    "eig_val, eig_vec = eig(A)\n",
    "print(eig_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See there is a eigenvalue (last one) equal to zero, which means A is a positive semi-definite matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.,  44.,   9.],\n",
       "       [ 44., 116.,  26.],\n",
       "       [  9.,  26.,   6.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = eig_vec\n",
    "Lambda = np.diag(eig_val)\n",
    "np.dot(np.dot(U,Lambda),U.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3AkYnPL5hhE"
   },
   "source": [
    "We could see that it satisfy the condition $A=U\\Lambda U^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a positive definite matrix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 10, 13],\n",
       "       [10, 14, 11],\n",
       "       [13, 11, 14]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,2,3],[3,2,1],[2,1,3]])\n",
    "A = np.dot(X,X.T)\n",
    "# Create a matrix A\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36.71375942  0.89273472  4.39350586]\n"
     ]
    }
   ],
   "source": [
    "eig_val, eig_vec = eig(A)\n",
    "print(eig_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See there is no eigenvalue equal to zero, which means A is a positive definite matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyh4AXqI5hhE"
   },
   "source": [
    "## Trace, determinant and Rank\n",
    "### Notations and Definition\n",
    "The trace of a matrix A is denoted $\\text{trace}(A)$ and is equal to the sum\n",
    "of its diagonal elements.\n",
    "The trace of a matrix is equal to the sum of its eigenvalues:\n",
    "$$\\text{trace}(A)=\\sum_i \\lambda_i$$\n",
    "The determinant of a matrix is also equal to the product of its eigenvalues:\n",
    "$$|A|=\\prod_i \\lambda_i$$\n",
    "Above, $\\lambda_i$ are the eigenvalues of $A$.\n",
    "\n",
    "Finally, the rank of a matrix is equivalent to the number of non-zero eigenvalues of the matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1u8jjJb5hhF"
   },
   "source": [
    "### Examples\n",
    "Firstly, we establish a semi-positive matrix $A$ by $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "659arEI35hhF",
    "outputId": "70381a15-1626-4897-bef3-0f937dc0e031",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21,  44,   9],\n",
       "       [ 44, 116,  26],\n",
       "       [  9,  26,   6]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,2,4],[4,8,6],[1,2,1]])\n",
    "A = np.dot(X,X.T)\n",
    "# Create a matrix A\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SF_a9l9A5hhF",
    "outputId": "71688772-732c-4c01-d916-ce6c93d50c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the eigenvalues of A are:\n",
      "[ 1.38933300e+02  4.06669962e+00 -1.41724797e-15]\n",
      "142.99999999999997\n",
      "the determinant of A is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-8.007451030949963e-13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_val, eig_vec = eig(A)\n",
    "print(\"the eigenvalues of A are:\")\n",
    "print(eig_val)\n",
    "print(np.sum(eig_val))\n",
    "print(\"the determinant of A is:\")\n",
    "np.prod(eig_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTs8ey5A5hhF",
    "outputId": "e752dc9a-af91-42c4-db46-ff9488aefc59",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the diagonal values of A are:\n",
      "[ 21 116   6]\n",
      "the trace of A: 143.000000\n"
     ]
    }
   ],
   "source": [
    "diag_A = np.diag(A)\n",
    "print(\"the diagonal values of A are:\")\n",
    "print(diag_A)\n",
    "trace_A = np.sum(diag_A)\n",
    "print(\"the trace of A: %f\" % trace_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXOFNtXD5hhF"
   },
   "source": [
    "We could see that it exists some calculation errors, yet the errors are quite small which are acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WBvsvIEk5hhG",
    "outputId": "bb27eb07-0954-4b06-ef3e-f2575475c40d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRqoAB-w5hhG"
   },
   "source": [
    "`np.linalg.matrix_rank`: a function to compute the rank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1t4A6FX5hhG"
   },
   "source": [
    "## Section 2: Singular Value Decomposition (SVD)\n",
    "### Notations and Definition\n",
    "SVD is a matrix factorisation method, which is an important concept of linear algebra. It is applied to the fields of data dimensionality reduction, recommendation system and natural language processing, and is also widely used in machine learning. The following section mainly introduces the definition and nature of SVD, calculation process and geometric interpretation.\n",
    "* SVD is defined as $$A = U\\Sigma V^T$$\n",
    "* $U\\in \\mathbb{R}^{m\\times m}$ is an orthogonal matrix, $V\\in \\mathbb{R}^{n\\times n}$ is also an orthogonal matrix , and $\\Sigma\\in \\mathbb{R}^{m\\times n} $ is a rectangular diagonal matrix composed of non-negative diagonal singular values sorted in descending order. Due to these properties, we have $UU^T = U^T U=I$, $VV^T=V^TV=I$, and $\\Sigma = diag(\\sigma_1,\\sigma_2,\\cdots,\\sigma_p),$ where $p= \\min(m,n)$. Note that a singular value is the square root of the respective eigenvalue. \n",
    "* Additionally, we also have the following properties $$A^{T} A=\\left(U \\Sigma V^{T}\\right)^{T}\\left(U \\Sigma V^{T}\\right)=V\\left(\\Sigma^{T} \\Sigma\\right) V^{T}=V\\Sigma^{2} V^{T}=V\\Lambda V^{T}$$\n",
    "$$A A^{T}=\\left(U \\Sigma V^{T}\\right)\\left(U \\Sigma V^{T}\\right)^{T}=U\\left(\\Sigma^{T} \\Sigma\\right) U^{T}=U\\Sigma^2U^{T}=U\\Lambda U^{T}$$\n",
    "* Moreover, $U$ consists of eignvectors of $AA^T$ and $V$ consists of eignvectors of $A^TA$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXERblhC5hhG"
   },
   "source": [
    "### Examples\n",
    "Firstly, we establish a semi-positive square matrix $A$ by $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JlPtyTP5hhH",
    "outputId": "db7b7b50-8035-43b3-c8bf-a8610364394c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21,  44,   9],\n",
       "       [ 44, 116,  26],\n",
       "       [  9,  26,   6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1,2,4],[4,8,6],[1,2,1]])\n",
    "A = np.dot(X,X.T)\n",
    "# Create a matrix A\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-_yloJJ5hhH",
    "outputId": "3a8c5650-c1d5-4c27-f996-6b124bd7580b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.,  44.,   9.],\n",
       "       [ 44., 116.,  26.],\n",
       "       [  9.,  26.,   6.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, sigma_vector, V_t = np.linalg.svd(A)\n",
    "Sigma = np.diag(sigma_vector)\n",
    "np.dot(np.dot(U,Sigma),V_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXXzyccp5hhH"
   },
   "source": [
    "`np.linalg.svd` could do SVD, where the ouput  $U$= `U`, $\\Sigma$=`np.diag(sigma_vector)` and $V^T$ = `V_t`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1f-ZjCK5hhI"
   },
   "source": [
    "## Lagrange multipliers\n",
    "\n",
    "For the following optimisation problem, we can use the method of Lagrange multipliers to solve it\n",
    "$$\\min f(\\boldsymbol x)$$\n",
    "subject to\n",
    "$$g(\\boldsymbol x) = 0 $$\n",
    "\n",
    "In this case, we can build a Lagrange function:\n",
    "$$\\mathcal{L}(x, \\lambda)=f(x)-\\lambda g(x)$$\n",
    "\n",
    "And the following optimisation problem is equal to the orginal one:\n",
    "$$\\min_{\\lambda,\\boldsymbol x}\\mathcal{L}(x, \\lambda)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyjPGjYt5hhI"
   },
   "source": [
    "That means, we now have to optimise the objective function with respect to $\\lambda$ and $\\boldsymbol x$. All we need to is to compute the partial derivatives with respect to $\\lambda$ and $\\boldsymbol x$, set them to zeros and solve the resulting joint equations for $\\lambda$ and $\\boldsymbol x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho-KKGp35hhI"
   },
   "source": [
    "### An example\n",
    "\n",
    "Let's have a look at one example. For instance, we want tackle the following constrained optimisation question:\n",
    "$$\\min_{x,y} 1 - x^2 - y^2 $$\n",
    "subject to\n",
    "$$ x + y - 1 = 0$$\n",
    "\n",
    "Fistly, we need to eastablish the Lagrange function \n",
    "$$\\mathcal{L}(x,y,\\lambda) = 1 - x^2 - y^2 -\\lambda(x + y - 1)$$\n",
    "\n",
    "Then the original problem is transformed into the following question:\n",
    "$$\\min_{x,y,\\lambda}\\mathcal{L}(x,y,\\lambda)$$\n",
    "\n",
    "We then differetiate the function with respect to $x$, $y$ and $\\lambda$ and set their partial derivative to zero,\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}(x,y,\\lambda)}{\\partial x}=0\\\\\n",
    "\\frac{\\partial \\mathcal{L}(x,y,\\lambda)}{\\partial y}=0\\\\\n",
    "\\frac{\\partial \\mathcal{L}(x,y,\\lambda)}{\\partial \\lambda}=0\n",
    "\\end{align}$$\n",
    "\n",
    "which implies\n",
    "\n",
    "$$\\begin{align}\n",
    " - 2 x - \\lambda = 0 \\\\\n",
    " - 2 y - \\lambda = 0\\\\\n",
    "  x + y - 1 = 0 \n",
    "\\end{align}$$\n",
    "\n",
    "Solution of these equations then gives $(x^*, y^*) = (\\frac{1}{2}, \\frac{1}{2})$ and $\\lambda = -1$.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "math_tutorial_x.j.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
